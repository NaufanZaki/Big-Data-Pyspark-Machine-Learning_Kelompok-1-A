{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2157,"sourceType":"datasetVersion","datasetId":18}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Analisis Amazon Fine Food Reviews dengan PySpark dan Random Forest**","metadata":{}},{"cell_type":"code","source":"# install\n!pip install findspark\n!pip install pyspark\nimport findspark\nfindspark.init()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-19T17:50:51.113514Z","iopub.execute_input":"2024-10-19T17:50:51.113993Z","iopub.status.idle":"2024-10-19T17:51:56.388173Z","shell.execute_reply.started":"2024-10-19T17:50:51.113902Z","shell.execute_reply":"2024-10-19T17:51:56.386288Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting findspark\n  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\nDownloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\nInstalling collected packages: findspark\nSuccessfully installed findspark-2.0.1\nCollecting pyspark\n  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840629 sha256=f7b84e92a3e74f89550528d16eb64f189e2da7dac24c986c5acec4a3c3bc8802\n  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.3\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:51:56.390530Z","iopub.execute_input":"2024-10-19T17:51:56.392146Z","iopub.status.idle":"2024-10-19T17:51:56.783450Z","shell.execute_reply.started":"2024-10-19T17:51:56.392084Z","shell.execute_reply":"2024-10-19T17:51:56.782167Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Start Spark session\nspark = SparkSession.builder.appName(\"Amazon Fine Food Reviews Classification\").getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:51:56.785346Z","iopub.execute_input":"2024-10-19T17:51:56.786031Z","iopub.status.idle":"2024-10-19T17:52:03.006743Z","shell.execute_reply.started":"2024-10-19T17:51:56.785966Z","shell.execute_reply":"2024-10-19T17:52:03.004680Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/10/19 17:52:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load dataset\ndf = spark.read.csv('/kaggle/input/amazon-fine-food-reviews/Reviews.csv', header=True, inferSchema=True)\n\n# Tampilkan beberapa baris pertama dataset\ndf.show(5)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:52:03.009854Z","iopub.execute_input":"2024-10-19T17:52:03.010369Z","iopub.status.idle":"2024-10-19T17:52:15.697310Z","shell.execute_reply.started":"2024-10-19T17:52:03.010313Z","shell.execute_reply":"2024-10-19T17:52:15.696296Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n| Id| ProductId|        UserId|         ProfileName|HelpfulnessNumerator|HelpfulnessDenominator|Score|      Time|             Summary|                Text|\n+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n|  1|B001E4KFG0|A3SGXH7AUHU8GW|          delmartian|                   1|                     1|    5|1303862400|Good Quality Dog ...|I have bought sev...|\n|  2|B00813GRG4|A1D87F6ZCVE5NK|              dll pa|                   0|                     0|    1|1346976000|   Not as Advertised|\"Product arrived ...|\n|  3|B000LQOCH0| ABXLMWJIXXAIN|\"Natalia Corres \"...|                   1|                     1|    4|1219017600|\"\"\"Delight\"\" says...|\"This is a confec...|\n|  4|B000UA0QIQ|A395BORC6FGVXV|                Karl|                   3|                     3|    2|1307923200|      Cough Medicine|If you are lookin...|\n|  5|B006K2ZZ7K|A1UQRSCLF8GW1T|\"Michael D. Bigha...|                   0|                     0|    5|1350777600|         Great taffy|Great taffy at a ...|\n+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\nonly showing top 5 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Hapus nilai null dari kolom 'Text' dan 'Score'\ndf = df.na.drop(subset=[\"Text\", \"Score\"])\n\n# Tokenisasi teks dan hapus stop words\ntokenizer = Tokenizer(inputCol=\"Text\", outputCol=\"words\")\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:52:15.698566Z","iopub.execute_input":"2024-10-19T17:52:15.699060Z","iopub.status.idle":"2024-10-19T17:52:15.884602Z","shell.execute_reply.started":"2024-10-19T17:52:15.699008Z","shell.execute_reply":"2024-10-19T17:52:15.883459Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Mengubah teks menjadi fitur TF-IDF\nhashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=10000)\nidf = IDF(inputCol=\"raw_features\", outputCol=\"features\")","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:52:15.886028Z","iopub.execute_input":"2024-10-19T17:52:15.886516Z","iopub.status.idle":"2024-10-19T17:52:15.913529Z","shell.execute_reply.started":"2024-10-19T17:52:15.886462Z","shell.execute_reply":"2024-10-19T17:52:15.912188Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Konversi kolom 'Score' menjadi label dan tangani label yang tidak terlihat\nlabel_indexer = StringIndexer(inputCol=\"Score\", outputCol=\"label\", handleInvalid=\"keep\")","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:52:15.914821Z","iopub.execute_input":"2024-10-19T17:52:15.915680Z","iopub.status.idle":"2024-10-19T17:52:15.934873Z","shell.execute_reply.started":"2024-10-19T17:52:15.915636Z","shell.execute_reply":"2024-10-19T17:52:15.933578Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Definisikan Random Forest Classifier\nrf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=50)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:52:15.936652Z","iopub.execute_input":"2024-10-19T17:52:15.937551Z","iopub.status.idle":"2024-10-19T17:52:15.981845Z","shell.execute_reply.started":"2024-10-19T17:52:15.937489Z","shell.execute_reply":"2024-10-19T17:52:15.980671Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Membuat pipeline untuk menggabungkan praproses dan model\npipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, label_indexer, rf])","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:52:15.983415Z","iopub.execute_input":"2024-10-19T17:52:15.984457Z","iopub.status.idle":"2024-10-19T17:52:15.991170Z","shell.execute_reply.started":"2024-10-19T17:52:15.984404Z","shell.execute_reply":"2024-10-19T17:52:15.989806Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Membagi data menjadi data pelatihan dan pengujian\ntrain_data, test_data = df.randomSplit([0.8, 0.2], seed=1234)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:52:15.995852Z","iopub.execute_input":"2024-10-19T17:52:15.996445Z","iopub.status.idle":"2024-10-19T17:52:16.042884Z","shell.execute_reply.started":"2024-10-19T17:52:15.996390Z","shell.execute_reply":"2024-10-19T17:52:16.041587Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Melatih model menggunakan data pelatihan\nmodel = pipeline.fit(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:52:16.044518Z","iopub.execute_input":"2024-10-19T17:52:16.045028Z","iopub.status.idle":"2024-10-19T17:57:45.414279Z","shell.execute_reply.started":"2024-10-19T17:52:16.044971Z","shell.execute_reply":"2024-10-19T17:57:45.412999Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"24/10/19 17:54:22 WARN MemoryStore: Not enough space to cache rdd_51_0 in memory! (computed 24.2 MiB so far)\n24/10/19 17:54:22 WARN BlockManager: Persisting block rdd_51_0 to disk instead.\n24/10/19 17:54:22 WARN MemoryStore: Not enough space to cache rdd_51_1 in memory! (computed 24.2 MiB so far)\n24/10/19 17:54:22 WARN BlockManager: Persisting block rdd_51_1 to disk instead.\n24/10/19 17:54:22 WARN MemoryStore: Not enough space to cache rdd_51_2 in memory! (computed 10.5 MiB so far)\n24/10/19 17:54:22 WARN BlockManager: Persisting block rdd_51_2 to disk instead.\n24/10/19 17:54:22 WARN MemoryStore: Not enough space to cache rdd_51_3 in memory! (computed 24.2 MiB so far)\n24/10/19 17:54:22 WARN BlockManager: Persisting block rdd_51_3 to disk instead.\n24/10/19 17:55:32 WARN MemoryStore: Not enough space to cache rdd_51_3 in memory! (computed 130.0 MiB so far)\n24/10/19 17:55:35 WARN MemoryStore: Not enough space to cache rdd_51_1 in memory! (computed 195.3 MiB so far)\n24/10/19 17:55:36 WARN MemoryStore: Not enough space to cache rdd_51_0 in memory! (computed 130.0 MiB so far)\n24/10/19 17:55:38 WARN MemoryStore: Not enough space to cache rdd_51_2 in memory! (computed 293.1 MiB so far)\n24/10/19 17:55:59 WARN MemoryStore: Not enough space to cache rdd_51_3 in memory! (computed 84.6 MiB so far)\n24/10/19 17:55:59 WARN MemoryStore: Not enough space to cache rdd_51_2 in memory! (computed 84.6 MiB so far)\n24/10/19 17:55:59 WARN MemoryStore: Not enough space to cache rdd_51_0 in memory! (computed 130.0 MiB so far)\n24/10/19 17:55:59 WARN MemoryStore: Not enough space to cache rdd_51_1 in memory! (computed 130.0 MiB so far)\n24/10/19 17:56:21 WARN MemoryStore: Not enough space to cache rdd_51_0 in memory! (computed 84.6 MiB so far)\n24/10/19 17:56:21 WARN MemoryStore: Not enough space to cache rdd_51_3 in memory! (computed 84.6 MiB so far)\n24/10/19 17:56:21 WARN MemoryStore: Not enough space to cache rdd_51_1 in memory! (computed 130.0 MiB so far)\n24/10/19 17:56:21 WARN MemoryStore: Not enough space to cache rdd_51_2 in memory! (computed 130.0 MiB so far)\n24/10/19 17:56:47 WARN DAGScheduler: Broadcasting large task binary with size 1316.0 KiB\n24/10/19 17:56:47 WARN MemoryStore: Not enough space to cache rdd_51_3 in memory! (computed 84.6 MiB so far)\n24/10/19 17:56:47 WARN MemoryStore: Not enough space to cache rdd_51_2 in memory! (computed 84.6 MiB so far)\n24/10/19 17:56:48 WARN MemoryStore: Not enough space to cache rdd_51_1 in memory! (computed 130.0 MiB so far)\n24/10/19 17:56:48 WARN MemoryStore: Not enough space to cache rdd_51_0 in memory! (computed 130.0 MiB so far)\n24/10/19 17:57:14 WARN DAGScheduler: Broadcasting large task binary with size 2011.8 KiB\n24/10/19 17:57:14 WARN MemoryStore: Not enough space to cache rdd_51_0 in memory! (computed 84.6 MiB so far)\n24/10/19 17:57:14 WARN MemoryStore: Not enough space to cache rdd_51_2 in memory! (computed 84.6 MiB so far)\n24/10/19 17:57:15 WARN MemoryStore: Not enough space to cache rdd_51_3 in memory! (computed 130.0 MiB so far)\n24/10/19 17:57:15 WARN MemoryStore: Not enough space to cache rdd_51_1 in memory! (computed 130.0 MiB so far)\n                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Membuat prediksi pada data pengujian\npredictions = model.transform(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:57:45.419978Z","iopub.execute_input":"2024-10-19T17:57:45.421259Z","iopub.status.idle":"2024-10-19T17:57:45.717416Z","shell.execute_reply.started":"2024-10-19T17:57:45.421177Z","shell.execute_reply":"2024-10-19T17:57:45.716022Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Evaluasi model dengan metrik akurasi\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(f\"Akurasi Model = {accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-19T17:57:45.719166Z","iopub.execute_input":"2024-10-19T17:57:45.720187Z","iopub.status.idle":"2024-10-19T17:58:00.968847Z","shell.execute_reply.started":"2024-10-19T17:57:45.720130Z","shell.execute_reply":"2024-10-19T17:58:00.967389Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"24/10/19 17:57:45 WARN DAGScheduler: Broadcasting large task binary with size 1628.6 KiB\n[Stage 21:===========================================>              (3 + 1) / 4]\r","output_type":"stream"},{"name":"stdout","text":"Akurasi Model = 0.64\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]}]}